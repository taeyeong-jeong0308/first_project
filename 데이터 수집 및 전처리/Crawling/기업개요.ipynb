import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time

def crawl_company_info(code):
    url = f"https://comp.fnguide.com/SVO2/asp/SVD_Corp.asp?pGB=1&gicode={code}"
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(url)
    time.sleep(2)
    data = []

    def extract(xpath):
        try:
            rows = driver.find_elements(By.XPATH, xpath)
            for row in rows:
                th = row.find_element(By.TAG_NAME, 'th').text.strip()
                td = row.find_element(By.TAG_NAME, 'td').text.strip()
                data.append([th, td])
        except:
            pass

    extract('//*[@id="corpGeneralInfo"]/table/tbody/tr')
    extract('//*[@id="compBody"]/div[4]/div[1]/table/tbody/tr')
    extract('//*[@id="compBody"]/div[4]/div[2]/table/tbody/tr')
    driver.quit()
    return pd.DataFrame(data, columns=["항목", "값"]).set_index("항목").T

sample_codes = ['A005930', 'A000660', 'A035420', 'A068270', 'A207940']
dfs = []
for code in sample_codes:
    df = crawl_company_info(code)
    df["종목코드"] = code
    dfs.append(df)
final_df = pd.concat(dfs, ignore_index=True)
final_df.to_csv("기업개요_샘플5개.csv", index=False, encoding='utf-8-sig')
print("✅ 저장 완료: 기업개요_샘플5개.csv")


import pandas as pd
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

filepath = "./데이터 수집 및 전처리/DART재무_코스피전체_2024기준 (1).xlsx"
df = pd.read_excel(filepath)
codes = df[['종목코드', '종목명']].dropna()
codes['종목코드'] = codes['종목코드'].astype(str).str.zfill(6)

options = Options()
options.add_argument('--headless')
options.add_argument('--disable-gpu')
options.add_argument('--no-sandbox')
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

results = []
total = len(codes)
for i, row in codes.iterrows():
    code = row['종목코드']
    name = row['종목명']
    url = f"https://comp.fnguide.com/SVO2/asp/SVD_Corp.asp?pGB=1&gicode=A{code}"
    try:
        driver.get(url)
        time.sleep(2)
        element = driver.find_element(By.XPATH, '//*[@id="corpGeneralInfo"]')
        text = element.text.strip()
        status = "성공"
    except Exception as e:
        text = f"오류 발생: {e}"
        status = "실패"
    results.append({'종목코드': code, '종목명': name, '기업개요': text})
    print(f"[{i+1}/{total}] {code} - {name} → {status}")
driver.quit()

output_path = "./데이터 수집 및 전처리/기업설명기업개요전체.csv"
result_df = pd.DataFrame(results)
result_df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"\n✅ 전체 크롤링 완료! 결과 저장 위치:\n{output_path}")

import re
df = pd.read_csv('./데이터 수집 및 전처리/기업설명기업개요전체.csv', dtype={'종목코드': str})

def extract_field(text, field):
    try:
        match = re.search(fr'{field}\n([^\n]+)', str(text))
        return match.group(1).strip() if match else None
    except:
        return None

def extract_phone(text):
    match = re.search(r'(\d{2,4}-\d{3,4}-\d{4})', str(text))
    return match.group(1) if match else None

def extract_homepage(text):
    match = re.search(r'(https?://[^\s\n]+)', str(text))
    return match.group(1) if match else None

df['주소'] = df['기업개요'].apply(lambda x: extract_field(x, '주소'))
df['설립일'] = df['기업개요'].apply(lambda x: extract_field(x, '설립일'))
df['대표자'] = df['기업개요'].apply(lambda x: extract_field(x, '대표자'))
df['전화번호'] = df['기업개요'].apply(extract_phone)
df['홈페이지'] = df['기업개요'].apply(extract_homepage)
df['설립연도'] = df['설립일'].apply(lambda x: str(x).split('-')[0] if pd.notnull(x) else None)

output_path = "기업개요_정리완료.csv"
df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"✅ 기업개요 정리 완료: {output_path}")
